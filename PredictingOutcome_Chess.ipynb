{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2de5870",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\">The Chess Whisperers</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325bfe3",
   "metadata": {},
   "source": [
    "## <h2 style=\"text-align: center;\">Problem Definition: Predicting Draw or Defeat</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a560dc5",
   "metadata": {},
   "source": [
    "### <h5>Background</h5>\n",
    "\n",
    "Chess is a strategic board game played between two players, and understanding the factors that contribute to winning a game can provide valuable insights into player performance. The availability of a dataset containing 6.25 million chess games played on lichess.org during July 2016 on <a href=\"https://www.kaggle.com/datasets/arevel/chess-games\">Kaggle</a> presents an opportunity to develop a predictive model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db42767",
   "metadata": {},
   "source": [
    "<h5>Problem Statement</h5>\n",
    "\n",
    "\n",
    "\n",
    "The primary objective of this project is to ascertain the ultimate result of the game, specifically whether White emerges as the winner, Black emerges as the winner, or if the game concludes in a draw by analyzing features such as player ratings, opening moves, and time control etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1e19e",
   "metadata": {},
   "source": [
    "<h5>Dataset & Description </h5>\n",
    "\n",
    "The dataset consists of 6.25 million chess games played on lichess.org in July 2016. It includes game attributes such as event type, player IDs, game result, date and time, player ratings, opening classification, time control, termination reason, and movements. Some games may have Stockfish analysis evaluations. For more specific details, please refer to the original dataset source at lichess.org.\n",
    "\n",
    "\n",
    "The dataset consists of the following attributes for each chess game:\n",
    "\n",
    "Event: The type of game.\\\n",
    "White: White player's ID.\\\n",
    "Black: Black player's ID.\\\n",
    "Result: Game result (1-0 for White win, 0-1 for Black win).\\\n",
    "UTCDate: Date of the game in UTC.\\\n",
    "UTCTime: Time of the game in UTC.\\\n",
    "WhiteElo: White player's ELO rating.\\\n",
    "BlackElo: Black player's ELO rating.\\\n",
    "WhiteRatingDiff: Difference in White player's rating after the game.\\\n",
    "BlackRatingDiff: Difference in Black player's rating after the game.\\\n",
    "ECO: Opening in ECO encoding.\\\n",
    "Opening: Opening name.\\\n",
    "TimeControl: Time control for each player in seconds.\\\n",
    "Termination: Reason for the game's end.\\\n",
    "AN: Movements in Movetext format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff29f3",
   "metadata": {},
   "source": [
    "## PySpark Environment Setup and Version Information\n",
    "\n",
    "This code snippet demonstrates the setup of a PySpark environment and provides the version information. It imports the necessary libraries, configures the SparkSession, and prints the version of Spark and PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5df703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Hadoop Info looging\n",
    "!sed -i 's/hadoop.root.logger=INFO,console/hadoop.root.logger=WARN,console/' /usr/hadoop-3.3.2/etc/hadoop/log4j.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1577de39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 01:57:28,824 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import *\n",
    "from itertools import chain\n",
    "from pyspark.ml.feature import * \n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "conf = pyspark.SparkConf().setAll([('spark.master', 'local[10]'),\n",
    "                                   ('spark.app.name', 'PySpark DataFrame Demo'),\n",
    "                                   ('spark.driver.memory', '8g'),\n",
    "                                   ('spark.executor.memory', '8g'),\n",
    "                                   ('spark.dynamicAllocation.enabled', 'true')])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4c838",
   "metadata": {},
   "source": [
    "## Reading a CSV File into a PySpark DataFrame\n",
    "\n",
    "This code snippet demonstrates reading a CSV file into a PySpark DataFrame. It utilizes the `spark.read.csv()` method with specified parameters to read the file and infer the schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7810b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#read data file\n",
    "data = spark.read.csv(path = 'file:///home/work/Chess Whisperers/chess_games.csv',header='True', inferSchema='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cce8a2",
   "metadata": {},
   "source": [
    "## Dropping Rows with Null Values from a PySpark DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311a8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954313d",
   "metadata": {},
   "source": [
    "## Dropping Columns from a PySpark DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d05bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "data = data.drop('White', 'Black', 'UTCDate', 'UTCTime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6658007",
   "metadata": {},
   "source": [
    "## Filtering Rows based on Column Values in a PySpark DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b7b16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data.Termination!='Abandoned')\n",
    "data = data.filter(data.Termination!='Rule Infraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c6919",
   "metadata": {},
   "source": [
    "## Modifying a Column in a PySpark DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf22866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.withColumn('Event', trim(data.Event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d684b24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------+--------+---------------+---------------+---+--------------------+-----------+------------+--------------------+\n",
      "|           Event|Result|WhiteElo|BlackElo|WhiteRatingDiff|BlackRatingDiff|ECO|             Opening|TimeControl| Termination|                  AN|\n",
      "+----------------+------+--------+--------+---------------+---------------+---+--------------------+-----------+------------+--------------------+\n",
      "|       Classical|   1-0|    1901|    1896|           11.0|          -11.0|D10|        Slav Defense|      300+5|Time forfeit|1. d4 d5 2. c4 c6...|\n",
      "|           Blitz|   0-1|    1641|    1627|          -11.0|           12.0|C20|King's Pawn Openi...|      300+0|      Normal|1. e4 e5 2. b3 Nf...|\n",
      "|Blitz tournament|   1-0|    1647|    1688|           13.0|          -13.0|B01|Scandinavian Defe...|      180+0|Time forfeit|1. e4 d5 2. exd5 ...|\n",
      "|  Correspondence|   1-0|    1706|    1317|           27.0|          -25.0|A00|Van't Kruijs Opening|          -|      Normal|1. e3 Nf6 2. Bc4 ...|\n",
      "|Blitz tournament|   0-1|    1945|    1900|          -14.0|           13.0|B90|Sicilian Defense:...|      180+0|Time forfeit|1. e4 c5 2. Nf3 d...|\n",
      "|Blitz tournament|   0-1|    1773|    1809|          -10.0|           10.0|C27|         Vienna Game|      180+0|      Normal|1. e4 e5 2. Nc3 d...|\n",
      "|Blitz tournament|   0-1|    1895|    1886|          -12.0|           12.0|B10|Caro-Kann Defense...|      180+0|Time forfeit|1. e4 c6 2. Nf3 d...|\n",
      "|Blitz tournament|   1-0|    2155|    2356|           20.0|          -20.0|D02|Queen's Pawn Game...|      180+0|      Normal|1. d4 d5 2. Nf3 N...|\n",
      "|Blitz tournament|   0-1|    2010|    2111|           -9.0|            9.0|A45|         Indian Game|      300+0|      Normal|1. d4 Nf6 2. Bf4 ...|\n",
      "|Blitz tournament|   1-0|    1764|    1773|           12.0|          -12.0|B01|Scandinavian Defe...|      180+0|Time forfeit|1. e4 d5 2. exd5 ...|\n",
      "|       Classical|   0-1|    1649|    1638|          -13.0|           11.0|C57|Italian Game: Two...|      900+3|      Normal|1. e4 e5 2. Nf3 N...|\n",
      "|       Classical|   1-0|    1630|    1500|            7.0|           -7.0|C41| Philidor Defense #3|      420+5|      Normal|1. e4 e5 2. Nf3 d...|\n",
      "|Blitz tournament|   1-0|    1833|    1837|           11.0|          -12.0|C36|King's Gambit Acc...|      300+0|      Normal|1. e4 e5 2. f4 ex...|\n",
      "|Blitz tournament|   1-0|    2020|    1979|           10.0|          -11.0|A00|      Polish Opening|      180+0|Time forfeit|1. b4 e6 2. Bb2 d...|\n",
      "|Blitz tournament|   0-1|    1581|    1616|          -12.0|           11.0|B01|Scandinavian Defe...|      180+0|Time forfeit|1. e4 d5 2. exd5 ...|\n",
      "|Blitz tournament|   0-1|    1879|    1868|          -13.0|           12.0|B01|Scandinavian Defe...|      180+0|      Normal|1. e4 d5 2. exd5 ...|\n",
      "|Blitz tournament|   1-0|    1963|    1979|           12.0|          -13.0|B10|Caro-Kann Defense...|      180+0|      Normal|1. e4 c6 2. Nf3 d...|\n",
      "|Blitz tournament|   1-0|    1751|    1712|           10.0|          -10.0|C62|Ruy Lopez: Steini...|      180+0|      Normal|1. e4 e5 2. Nf3 N...|\n",
      "|Blitz tournament|   0-1|    1795|    1800|          -14.0|           11.0|B32|Sicilian Defense:...|      300+0|      Normal|1. e4 c5 2. Nf3 e...|\n",
      "|Blitz tournament|   1-0|    1913|    1925|           11.0|          -13.0|B12|Caro-Kann Defense...|      300+0|      Normal|1. e4 c6 2. d4 d5...|\n",
      "+----------------+------+--------+--------+---------------+---------------+---+--------------------+-----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db2571a",
   "metadata": {},
   "source": [
    "## Predicting game outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d0a9b",
   "metadata": {},
   "source": [
    "### Data Prep for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af4a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaking down the 'AN' column to extract information\n",
    "\n",
    "df  = df.withColumn(\"Moves\", regexp_replace(col(\"AN\"), \"\\\\d+\\\\.\", \"\"))\n",
    "df = df.withColumn(\"Moves\", split(col(\"Moves\"), \"  \"))\n",
    "df = df.withColumn(\"MoveArray\", transform(col(\"Moves\"), lambda x:split(x, \",\") ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e6e81",
   "metadata": {},
   "source": [
    "### Using Mapping, String Indexer to convert String features to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f58cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#String 'event' to integer\n",
    "eventDict = {'Bullet':0,'Classical tournament':1,'Bullet tournament':2,'Blitz':3,'Classical':4,'Blitz tournament':5, 'Correspondence':6}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*eventDict.items())])\n",
    "df = df.withColumn('Event', mapping_expr[df['Event']])\n",
    "\n",
    "#String 'Result' to integer\n",
    "resDict = {'1-0':0,'0-1':1,'1/2-1/2':2}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*resDict.items())])\n",
    "df = df.withColumn('Result', mapping_expr[df['Result']])\n",
    "\n",
    "#String 'termination' to integer\n",
    "termDict = {'Normal':0,'Time forfeit':1}\n",
    "mapping_expr = create_map([lit(x) for x in chain(*termDict.items())])\n",
    "df = df.withColumn('Termination', mapping_expr[df['Termination']])\n",
    "\n",
    "#Breaking down TimeControl into Time and control columns\n",
    "df = df.withColumn(\"Time\", split(col(\"TimeControl\"), \"\\+\").getItem(0).cast(\"int\"))\n",
    "df = df.withColumn(\"Control\", split(col(\"TimeControl\"), \"\\+\").getItem(1).cast(\"int\"))\n",
    "\n",
    "#Using string indexer to convert openings to integers\n",
    "opening_indexer = StringIndexer(inputCol=\"Opening\", outputCol=\"openingIndex\")\n",
    "df = opening_indexer.fit(df).transform(df)\n",
    "\n",
    "#Using string indexer to convert \"ECO\" to integers\n",
    "eco_indexer = StringIndexer(inputCol=\"ECO\", outputCol=\"ecoIndex\")\n",
    "df = eco_indexer.fit(df).transform(df)\n",
    "\n",
    "#dropping nulls before vectorizing\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedaf93a",
   "metadata": {},
   "source": [
    "### Creating a vectorized column using Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2abbb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols1 = ['Event','Termination','WhiteElo','BlackElo','openingIndex','Time','Control']\n",
    "outputCol = 'features'\n",
    "vec = VectorAssembler(inputCols = inputCols1, outputCol = outputCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19126380",
   "metadata": {},
   "source": [
    "### Scaling data in order for the classification model to interpret the features on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a027e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler_4b9e3473e7c3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = StandardScaler()\n",
    "std.setInputCol(\"features\")\n",
    "std.setOutputCol(\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8456b3",
   "metadata": {},
   "source": [
    "### Splitting data into Train and Test sets using sampleBy to do a stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50eea67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sampleBy(\"Result\", fractions={0: 0.6, 1: 0.6, 2:0.6}, seed=30)\n",
    "non_train = df.subtract(train)\n",
    "\n",
    "val = non_train.sampleBy(\"Result\", fractions={0: 0.5, 1: 0.5, 2:0.5}, seed=30)\n",
    "test = non_train.subtract(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb79bf",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e0354",
   "metadata": {},
   "source": [
    "**Model Selection using validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7971270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 01:58:46,422 WARN netlib.InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "2023-06-06 01:58:46,424 WARN netlib.InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'scaledFeatures', labelCol = 'Result')\n",
    "#DecisionTreeClassifier - maxbins = 3000 because 'openings' column has 2940 rows\n",
    "dt = DecisionTreeClassifier(featuresCol = 'scaledFeatures', labelCol = 'Result')\n",
    "dt.setMaxBins(3000)\n",
    "#RandomForestClassifier - maxbins = 3000 because 'openings' column has 2940 rows\n",
    "rf = RandomForestClassifier(featuresCol = 'scaledFeatures', labelCol = 'Result')\n",
    "rf.setMaxBins(3000)\n",
    "#NaiveBayes\n",
    "nb = NaiveBayes(featuresCol = 'scaledFeatures', labelCol = 'Result')\n",
    "\n",
    "#Building pipeline with stages - VectorAssembler, StandardScaler, Classification model\n",
    "lr_pipeline = Pipeline(stages=[vec, std, lr])\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "\n",
    "dt_pipeline = Pipeline(stages=[vec, std, dt])\n",
    "dt_model = dt_pipeline.fit(train)\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[vec, std, rf])\n",
    "rf_model = rf_pipeline.fit(train)\n",
    "\n",
    "nb_pipeline = Pipeline(stages=[vec, std, nb])\n",
    "nb_model = nb_pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2848f",
   "metadata": {},
   "source": [
    "**Using Multiclass Classification Evaluation for determining validation error**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16320aee",
   "metadata": {
    "tags": []
   },
   "source": [
    "Multiclass Classification Evaluation - Accuracy\n",
    "The logistic regression classifier was evaluated using the multiclass classification evaluator, specifically measuring the accuracy metric. The resulting accuracy value is 67.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c846a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\t 0.6307109071905614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\t 0.6130811561200054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\t 0.6191896466480604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 160:===========================================>          (54 + 10) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\t 0.5284891108466371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "evaluator.setLabelCol(\"Result\")\n",
    "\n",
    "print(\"Logistic Regression:\\t\", evaluator.evaluate(lr_model.transform(val), {evaluator.metricName: \"accuracy\"}))\n",
    "\n",
    "print(\"Decision Tree Classifier:\\t\", evaluator.evaluate(dt_model.transform(val), {evaluator.metricName: \"accuracy\"}))\n",
    "\n",
    "print(\"Random Forest:\\t\", evaluator.evaluate(rf_model.transform(val), {evaluator.metricName: \"accuracy\"}))\n",
    "\n",
    "print(\"Naive Bayes:\\t\",evaluator.evaluate(nb_model.transform(val), {evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb99b4e",
   "metadata": {},
   "source": [
    "**Trying with other metrics since accuracy is not the right metric for unbalanced data (Class 2 is very less in number)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e57c54",
   "metadata": {},
   "source": [
    "**F1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdcf1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\t 0.6178412483928153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\t 0.6005251128522024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\t 0.6041533625348708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\t 0.48960747631117685\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\\t\", evaluator.evaluate(lr_model.transform(val), {evaluator.metricName: \"f1\"}))\n",
    "\n",
    "print(\"Decision Tree Classifier:\\t\", evaluator.evaluate(dt_model.transform(val), {evaluator.metricName: \"f1\"}))\n",
    "\n",
    "print(\"Random Forest:\\t\", evaluator.evaluate(rf_model.transform(val), {evaluator.metricName: \"f1\"}))\n",
    "\n",
    "print(\"Naive Bayes:\\t\",evaluator.evaluate(nb_model.transform(val), {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a10614d",
   "metadata": {},
   "source": [
    "**WeightedPrecision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0b40aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\t 0.6064023290336455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\t 0.5893189396889758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\t 0.5972605250108711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 240:=================================================>     (60 + 7) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\t 0.5172610088691507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression:\\t\", evaluator.evaluate(lr_model.transform(val), {evaluator.metricName: \"weightedPrecision\"}))\n",
    "\n",
    "print(\"Decision Tree Classifier:\\t\", evaluator.evaluate(dt_model.transform(val), {evaluator.metricName: \"weightedPrecision\"}))\n",
    "\n",
    "print(\"Random Forest:\\t\", evaluator.evaluate(rf_model.transform(val), {evaluator.metricName: \"weightedPrecision\"}))\n",
    "\n",
    "print(\"Naive Bayes:\\t\",evaluator.evaluate(nb_model.transform(val), {evaluator.metricName: \"weightedPrecision\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da718b5",
   "metadata": {},
   "source": [
    "## Improving the model with new features extracted from existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f252b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using udfs to split moves as White move and black move\n",
    "split_white_udf = udf(lambda arr: [elem.split()[0] for [elem] in arr], ArrayType(StringType()))\n",
    "split_black_udf = udf(lambda arr: [elem.split()[1] for [elem] in arr], ArrayType(StringType()))\n",
    "\n",
    "df = df.withColumn(\"WhiteMoves\", split_white_udf(df.MoveArray))\n",
    "df = df.withColumn(\"BlackMoves\", split_black_udf(df.MoveArray))\n",
    "\n",
    "#Determining number of checks on each side\n",
    "df = df.withColumn(\"WhiteChecks\", transform(col(\"WhiteMoves\"), lambda x: length(regexp_replace(x, \"[^+]\", \"\"))))\n",
    "df = df.withColumn(\"NumOfWhiteChecks\", aggregate(\"WhiteChecks\", lit(0), lambda acc, x: acc + x))\n",
    "\n",
    "df = df.withColumn(\"BlackChecks\", transform(col(\"BlackMoves\"), lambda x: length(regexp_replace(x, \"[^+]\", \"\"))))\n",
    "df = df.withColumn(\"NumOfBlackChecks\", aggregate(\"BlackChecks\", lit(0), lambda acc, x: acc + x))\n",
    "\n",
    "#Determining if castling happened on each side\n",
    "df = df.withColumn(\"WhiteQueenCastling\", expr(\"array_contains(WhiteMoves, 'O-O')\"))\n",
    "df = df.withColumn(\"BlackQueenCastling\", expr(\"array_contains(BlackMoves, 'O-O')\"))\n",
    "\n",
    "df = df.withColumn(\"WhiteKingCastling\", expr(\"array_contains(WhiteMoves, 'O-O-O')\"))\n",
    "df = df.withColumn(\"BlackKingCastling\", expr(\"array_contains(BlackMoves, 'O-O-O')\"))\n",
    "\n",
    "df = df.withColumn(\"WhiteQueenCastling\", when(col(\"WhiteQueenCastling\"), 0).otherwise(1))\n",
    "df = df.withColumn(\"BlackQueenCastling\", when(col(\"BlackQueenCastling\"), 0).otherwise(1))\n",
    "\n",
    "df = df.withColumn(\"WhiteKingCastling\", when(col(\"WhiteKingCastling\"), 0).otherwise(1))\n",
    "df = df.withColumn(\"BlackKingCastling\", when(col(\"BlackKingCastling\"), 0).otherwise(1))\n",
    "\n",
    "#dropping nulls before vectorizing\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a99696",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols1 = ['Event','Termination','openingIndex','Time','Control','WhiteElo','BlackElo','NumOfWhiteChecks','NumOfBlackChecks','WhiteQueenCastling','BlackQueenCastling','WhiteKingCastling','BlackKingCastling']\n",
    "outputCol = 'new_features'\n",
    "vec = VectorAssembler(inputCols = inputCols1, outputCol = outputCol)\n",
    "df = vec.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46a39c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "std = StandardScaler()\n",
    "std.setInputCol(\"new_features\")\n",
    "std.setOutputCol(\"scalednewFeatures\")\n",
    "std_df = std.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a4a9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = std_df.sampleBy(\"Result\", fractions={0: 0.7, 1: 0.7, 2:0.7}, seed=30)\n",
    "test = std_df.subtract(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f934bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:================================>                     (20 + 10) / 33]\r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol = 'scalednewFeatures', labelCol = 'Result')\n",
    "lr_model = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "evaluator.setLabelCol(\"Result\")\n",
    "evaluator.evaluate(lr_model.transform(test), {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e35554",
   "metadata": {},
   "source": [
    "**Trying with other metrics since accuracy is not the right metric for unbalanced data (Class 2 is very less in number)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate(lr_model.transform(test), {evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773457a",
   "metadata": {},
   "source": [
    "## Binary Classification Evaluation (Just to feed the curiosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b533a6",
   "metadata": {},
   "source": [
    "This model works slightly better with just two classes. So we drop the class 2 which is Draws to determine the accuracy.\n",
    "In this evaluation, the logistic regression classifier achieved a ROC AUC value of 70%. \n",
    "The ROC AUC is a metric that quantifies the classifier's ability to rank positive instances higher than negative instances across various classification thresholds. A higher ROC AUC value indicates better discrimination between the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b75979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.filter(train.Result!=2)\n",
    "test = test.filter(test.Result!=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train)\n",
    "y_pred = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddc7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='Result')\n",
    "res.evaluate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab785d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b2516",
   "metadata": {},
   "source": [
    "**Coefficients clearly indicate the effect of each feature. It can be observed that newly added features NumOfWhiteChecks and NumOfBlackChecks have importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300213d1",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014fbda",
   "metadata": {},
   "source": [
    "* Collect more descriptive data, analyse and redo model selection with hyperparameter tuning\n",
    "\n",
    "* Incorporate player dynamics : Analyze player ratings over time to capture player performance trends or fluctuations that may affect game outcomes\n",
    "\n",
    "* Analysis of  how time investment in each move affects the results\n",
    "\n",
    "* Analyse if there are moves that boost the player ratings\n",
    "\n",
    "* Blunders or Brilliant moves, which are more correlated with the result?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
